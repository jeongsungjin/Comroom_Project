#!/usr/bin/env python3
"""
YOLO v8 í”„ë¦¬íŠ¸ë ˆì¸ ëª¨ë¸ ì¶”ë¡  í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
ì¹´ë©”ë¼ê°€ ì—†ì–´ë„ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ë¡œ í™•ì¸ ê°€ëŠ¥
"""
import sys
from pathlib import Path
import cv2
from ultralytics import YOLO

# í”„ë¡œì íŠ¸ ë£¨íŠ¸
PROJECT_ROOT = Path(__file__).parent.absolute()
WEIGHTS_PATH = PROJECT_ROOT / "weights" / "yolov8l.pt"

print("=" * 60)
print("YOLO v8 í”„ë¦¬íŠ¸ë ˆì¸ ëª¨ë¸ ì¶”ë¡  í…ŒìŠ¤íŠ¸")
print("=" * 60)

# ëª¨ë¸ ë¡œë“œ
if not WEIGHTS_PATH.exists():
    print(f"âŒ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {WEIGHTS_PATH}")
    print("   ë¨¼ì € ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œí•˜ì„¸ìš”:")
    print("   python3 -c \"from ultralytics import YOLO; YOLO('yolov8l.pt')\"")
    sys.exit(1)

print(f"ğŸ“¦ ëª¨ë¸ ë¡œë“œ ì¤‘: {WEIGHTS_PATH}")
model = YOLO(str(WEIGHTS_PATH))
print("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")

# ì¹´ë©”ë¼ í…ŒìŠ¤íŠ¸
print("\nğŸ“¹ ì¹´ë©”ë¼ ì—°ê²° í…ŒìŠ¤íŠ¸...")
cap = cv2.VideoCapture(0)
if cap.isOpened():
    ret, frame = cap.read()
    if ret:
        print("âœ… ì¹´ë©”ë¼ ì—°ê²° ì„±ê³µ!")
        print(f"   í•´ìƒë„: {frame.shape[1]}x{frame.shape[0]}")
        
        # ì¶”ë¡  í…ŒìŠ¤íŠ¸
        print("\nğŸ” ì¶”ë¡  í…ŒìŠ¤íŠ¸ ì¤‘...")
        results = model.predict(frame, imgsz=640, conf=0.5, device='cpu', verbose=False)
        
        # ê²°ê³¼ í™•ì¸
        annotated = results[0].plot()
        num_detections = len(results[0].boxes) if results[0].boxes is not None else 0
        print(f"âœ… íƒì§€ëœ ê°ì²´ ìˆ˜: {num_detections}")
        
        if num_detections > 0:
            print("\nğŸ“Š íƒì§€ ê²°ê³¼:")
            for i, box in enumerate(results[0].boxes):
                cls = int(box.cls[0])
                conf = float(box.conf[0])
                name = results[0].names[cls]
                x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                cx, cy = (x1 + x2) / 2, (y1 + y2) / 2
                print(f"  {i+1}. {name} (ì‹ ë¢°ë„: {conf:.2f}) - ì¤‘ì‹¬: ({cx:.1f}, {cy:.1f})")
        
        # ê²°ê³¼ ì´ë¯¸ì§€ ì €ì¥
        output_path = PROJECT_ROOT / "test_inference_result.jpg"
        cv2.imwrite(str(output_path), annotated)
        print(f"\nğŸ’¾ ê²°ê³¼ ì´ë¯¸ì§€ ì €ì¥: {output_path}")
        
        print("\nâœ… ì‹¤ì‹œê°„ ì¶”ë¡  ìŠ¤í¬ë¦½íŠ¸ê°€ ì •ìƒ ì‘ë™í•©ë‹ˆë‹¤!")
        print("   ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ì‹¤ì‹œê°„ ì¶”ë¡ ì„ ì‹¤í–‰í•˜ì„¸ìš”:")
        print("   python3 realtime_infer.py --weights weights/yolov8l.pt --show --fps")
    else:
        print("âš ï¸  ì¹´ë©”ë¼ì—ì„œ í”„ë ˆì„ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
    cap.release()
else:
    print("âš ï¸  ì¹´ë©”ë¼ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ (ì¹´ë©”ë¼ê°€ ì—°ê²°ë˜ì–´ ìˆì§€ ì•Šê±°ë‚˜ ë‹¤ë¥¸ í”„ë¡œê·¸ë¨ì´ ì‚¬ìš© ì¤‘)")
    print("\nğŸ“¸ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ë¡œ ì¶”ë¡  í…ŒìŠ¤íŠ¸...")
    
    # dataset í´ë”ì˜ ì´ë¯¸ì§€ë¡œ í…ŒìŠ¤íŠ¸
    test_images = list((PROJECT_ROOT / "dataset").glob("*.jpg"))
    if test_images:
        test_img = test_images[0]
        print(f"   í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€: {test_img.name}")
        img = cv2.imread(str(test_img))
        
        results = model.predict(img, imgsz=640, conf=0.5, device='cpu', verbose=False)
        annotated = results[0].plot()
        
        num_detections = len(results[0].boxes) if results[0].boxes is not None else 0
        print(f"âœ… íƒì§€ëœ ê°ì²´ ìˆ˜: {num_detections}")
        
        output_path = PROJECT_ROOT / "test_inference_result.jpg"
        cv2.imwrite(str(output_path), annotated)
        print(f"ğŸ’¾ ê²°ê³¼ ì´ë¯¸ì§€ ì €ì¥: {output_path}")
        print("\nâœ… ì¶”ë¡  ìŠ¤í¬ë¦½íŠ¸ê°€ ì •ìƒ ì‘ë™í•©ë‹ˆë‹¤!")
    else:
        print("âŒ í…ŒìŠ¤íŠ¸í•  ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

print("\n" + "=" * 60)

